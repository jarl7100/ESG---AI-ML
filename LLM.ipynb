{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37449065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from decouple import config\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langgraph.graph import START, StateGraph\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "import litellm\n",
    "from litellm import completion\n",
    "import instructor\n",
    "from instructor import Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fa4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_API_KEY = os.getenv('WX_API_KEY')\n",
    "WX_PROJECT_ID = os.getenv('WX_PROJECT_ID')\n",
    "WX_API_URL = \"https://us-south.ml.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3438a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def load_company_data(data_dir=\"data\", companies=None):\n",
    "    \"\"\"\n",
    "    Load 10-K and ESG data for companies from the structured directory.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Base data directory\n",
    "        companies: List of company names to load (None = all companies)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with company data organized by company and document type\n",
    "    \"\"\"\n",
    "    if companies is None:\n",
    "        # Get all company directories\n",
    "        companies = [d for d in os.listdir(data_dir) \n",
    "                    if os.path.isdir(os.path.join(data_dir, d)) \n",
    "                    and d not in ['ESG_frameworks', 'ESG_frameworks_txt', 'apiData', 'esg_report']]\n",
    "    \n",
    "    company_data = {}\n",
    "    \n",
    "    for company in companies:\n",
    "        company_dir = os.path.join(data_dir, company)\n",
    "        if not os.path.exists(company_dir):\n",
    "            print(f\"Warning: Directory {company_dir} not found\")\n",
    "            continue\n",
    "            \n",
    "        company_data[company] = {\n",
    "            '10k_documents': [],\n",
    "            'esg_documents': [],\n",
    "            'all_documents': []\n",
    "        }\n",
    "        \n",
    "        # Load 10-K documents\n",
    "        for item in ['10k_item1.md', '10k_item1A.md', '10k_item7.md', '10k_item7A.md']:\n",
    "            file_path = os.path.join(company_dir, item)\n",
    "            if os.path.exists(file_path):\n",
    "                docs = TextLoader(file_path).load()\n",
    "                for doc in docs:\n",
    "                    doc.metadata['company'] = company\n",
    "                    doc.metadata['document_type'] = '10k'\n",
    "                    doc.metadata['item'] = item.replace('10k_', '').replace('.md', '')\n",
    "                company_data[company]['10k_documents'].extend(docs)\n",
    "                company_data[company]['all_documents'].extend(docs)\n",
    "        \n",
    "        # Load ESG report\n",
    "        esg_path = os.path.join(company_dir, 'ESG_Report.md')\n",
    "        if os.path.exists(esg_path):\n",
    "            docs = TextLoader(esg_path).load()\n",
    "            for doc in docs:\n",
    "                doc.metadata['company'] = company\n",
    "                doc.metadata['document_type'] = 'esg_report'\n",
    "            company_data[company]['esg_documents'].extend(docs)\n",
    "            company_data[company]['all_documents'].extend(docs)\n",
    "        \n",
    "        print(f\"{company}: {len(company_data[company]['10k_documents'])} 10-K docs, \"\n",
    "              f\"{len(company_data[company]['esg_documents'])} ESG docs\")\n",
    "    \n",
    "    return company_data\n",
    "\n",
    "# Load all company data\n",
    "company_data = load_company_data()\n",
    "print(f\"\\nLoaded data for companies: {list(company_data.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7617282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = WatsonxLLM(\n",
    "\n",
    "        model_id= \"ibm/granite-3-8b-instruct\",\n",
    "        url=WX_API_URL,\n",
    "        apikey=WX_API_KEY,\n",
    "        project_id=WX_PROJECT_ID,\n",
    "\n",
    "        params={\n",
    "            GenParams.DECODING_METHOD: \"greedy\",\n",
    "            GenParams.TEMPERATURE: 0,\n",
    "            GenParams.MIN_NEW_TOKENS: 5,\n",
    "            GenParams.MAX_NEW_TOKENS: 1_000,\n",
    "            GenParams.REPETITION_PENALTY:1.2\n",
    "        }\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c823254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.outputs.llm_result.LLMResult'>\n",
      "generations=[[Generation(text=\"\\nI'm an artificial intelligence and don't have feelings, but I'm here to help you. How can I assist you today?\", generation_info={'finish_reason': 'eos_token'})]] llm_output={'token_usage': {'generated_token_count': 31, 'input_token_count': 5}, 'model_id': 'ibm/granite-3-8b-instruct', 'deployment_id': None} run=[RunInfo(run_id=UUID('038e0b3a-36ad-4221-b32a-d29eece330e9'))] type='LLMResult'\n"
     ]
    }
   ],
   "source": [
    "llm_result = llm.generate([\"Hi how are you?\"])\n",
    "\n",
    "print(type(llm_result))\n",
    "print(llm_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd6e4841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 10-K documents\n",
      "Loaded 0 ESG framework documents\n",
      "First 10-K document metadata: {'source': 'data/apiData/tsla_10k_item1.md'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "\n",
    "# Load all .txt files from the ESG frameworks directory\n",
    "esg_frameworks_dir = \"data/ESG_frameworks_txt\"\n",
    "esg_documents = []\n",
    "for fname in os.listdir(esg_frameworks_dir):\n",
    "    if fname.endswith(\".txt\"):\n",
    "        path = os.path.join(esg_frameworks_dir, fname)\n",
    "        esg_documents.extend(TextLoader(path).load())\n",
    "\n",
    "# Load all .md files from the apiData directory (Tesla 10-K data)\n",
    "tenk_dir = \"data/apiData\"\n",
    "tenk_documents = []\n",
    "for fname in os.listdir(tenk_dir):\n",
    "    if fname.endswith(\".md\"):\n",
    "        path = os.path.join(tenk_dir, fname)\n",
    "        tenk_documents.extend(TextLoader(path).load())\n",
    "\n",
    "print(f\"Loaded {len(tenk_documents)} 10-K documents\")\n",
    "print(f\"Loaded {len(esg_documents)} ESG framework documents\")\n",
    "if tenk_documents:\n",
    "    print(\"First 10-K document metadata:\", tenk_documents[0].metadata)\n",
    "if esg_documents:\n",
    "    print(\"First ESG document metadata:\", esg_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43684027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 334 10-K chunks\n",
      "Created 0 ESG framework chunks\n",
      "First 10-K chunk: # ITEM 1.\n",
      "\n",
      "BUSINESS\n",
      "\n",
      "Overview...\n",
      "No ESG framework chunks available\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Example: split 10-K documents into 1000-character chunks with 200 overlap\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Split 10-K documents\n",
    "tenk_chunks = []\n",
    "for doc in tenk_documents:\n",
    "    tenk_chunks.extend(splitter.split_documents([doc]))\n",
    "\n",
    "# Split ESG framework documents\n",
    "esg_chunks = []\n",
    "for doc in esg_documents:\n",
    "    esg_chunks.extend(splitter.split_documents([doc]))\n",
    "\n",
    "print(f\"Created {len(tenk_chunks)} 10-K chunks\")\n",
    "print(f\"Created {len(esg_chunks)} ESG framework chunks\")\n",
    "\n",
    "if tenk_chunks:\n",
    "    print(f\"First 10-K chunk: {tenk_chunks[0].page_content[:200]}...\")\n",
    "else:\n",
    "    print(\"No 10-K chunks available\")\n",
    "\n",
    "if esg_chunks:\n",
    "    print(f\"First ESG chunk: {esg_chunks[0].page_content[:200]}...\")\n",
    "else:\n",
    "    print(\"No ESG framework chunks available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b4537be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_params = {}\n",
    "\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/granite-embedding-278m-multilingual\",\n",
    "    url=WX_API_URL,\n",
    "    project_id=WX_PROJECT_ID,\n",
    "    apikey=WX_API_KEY,\n",
    "    params=embed_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a05fcf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chroma vector index for 10-K chunks\n",
    "tenk_vector_db = Chroma.from_documents(\n",
    "    collection_name=\"tenk_collection\",\n",
    "    embedding=watsonx_embedding,\n",
    "    persist_directory=\"tenk_vector_db\",\n",
    "    documents=tenk_chunks,\n",
    ")\n",
    "\n",
    "# Create a Chroma vector index for ESG framework chunks\n",
    "esg_vector_db = Chroma.from_documents(\n",
    "    collection_name=\"esg_collection\",\n",
    "    embedding=watsonx_embedding,\n",
    "    persist_directory=\"esg_vector_db\",\n",
    "    documents=esg_chunks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "935b0a5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local_vector_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Use the vectorstore as a retriever\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m retriever = \u001b[43mlocal_vector_db\u001b[49m.as_retriever(\n\u001b[32m      3\u001b[39m     search_type=\u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     search_kwargs={\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m,\n\u001b[32m      6\u001b[39m     }\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'local_vector_db' is not defined"
     ]
    }
   ],
   "source": [
    "# Use the vectorstore as a retriever\n",
    "retriever = local_vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "ID: eb2e6281-c167-4b91-a0cd-e621fc50e7fa\n",
      "Content: ESG\n",
      "The very purpose of Tesla's existence is to accelerate the world's transition to sustainable energy. We believe the world cannot reduce carbon emissions without addressing both energy\n",
      "generation and consumption, and we are designing and manufacturing a complete energy and transportation ecosystem to achieve this goal. As we expand, we are building each new factory to\n",
      "be more efficient and sustainably designed than the previous one, including with respect to per-unit waste reduction and resou\n",
      "\n",
      "################################################################################\n",
      "ID: 16b81130-0a94-4934-b2f7-96848ae75494\n",
      "Content: ESG\n",
      "The very purpose of Tesla's existence is to accelerate the world's transition to sustainable energy. We believe the world cannot reduce carbon emissions without addressing both energy\n",
      "generation and consumption, and we are designing and manufacturing a complete energy and transportation ecosystem to achieve this goal. As we expand, we are building each new factory to\n",
      "be more efficient and sustainably designed than the previous one, including with respect to per-unit waste reduction and resou\n",
      "\n",
      "################################################################################\n",
      "ID: 17e881a5-97d3-47ba-82d9-ce95d8e67d5b\n",
      "Content: ESG\n",
      "The very purpose of Tesla's existence is to accelerate the world's transition to sustainable energy. We believe the world cannot reduce carbon emissions without addressing both energy\n",
      "generation and consumption, and we are designing and manufacturing a complete energy and transportation ecosystem to achieve this goal. As we expand, we are building each new factory to\n",
      "be more efficient and sustainably designed than the previous one, including with respect to per-unit waste reduction and resou\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Retrieve the most similar text\n",
    "retrieved_documents = retriever.invoke(\"What is the purpose of the ESG framework?\")\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(f\"{'#' * 80}\\nID: {document.id}\")\n",
    "    first_n_of_content = document.page_content[:500].replace('\\n\\n', ' ')\n",
    "    print(f\"Content: {first_n_of_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ecd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a highly accurate ESG disclosure evaluator, trained to assess company filings for the presence, quality, and materiality of ESG (Environmental, Social, Governance) information.\n",
    "\n",
    "Your task is to analyze retrieved excerpts from 10-K filings and provide a structured evaluation for each ESG dimension or sub-category.\n",
    "\n",
    "You are expected to:\n",
    "1. Identify whether the passage addresses a relevant ESG topic (defined below).\n",
    "2. Judge the quality and detail of the disclosure (is it specific, quantitative, and forward-looking, or vague and generic?).\n",
    "3. Assign a score between 0 and 5 based on the scoring rubric.\n",
    "4. Justify your score in a concise explanation, quoting or paraphrasing the evidence from the text.\n",
    "\n",
    "### ESG Dimensions and Categories (based on LSEG/SASB):\n",
    "\n",
    "**Environmental:**\n",
    "- Emissions (e.g. CO₂ reporting, reduction targets)\n",
    "- Resource Use (e.g. energy/water consumption)\n",
    "- Innovation (e.g. green technologies)\n",
    "\n",
    "**Social:**\n",
    "- Workforce (e.g. diversity, DEI initiatives, labor practices)\n",
    "- Human Rights (e.g. supply chain policies)\n",
    "- Community Engagement (e.g. philanthropy, local impact)\n",
    "- Product Responsibility (e.g. product safety, consumer protection)\n",
    "\n",
    "**Governance:**\n",
    "- Management (e.g. executive structure, board diversity, oversight)\n",
    "- CSR Strategy (e.g. ESG integration into business strategy)\n",
    "- Shareholders (e.g. voting rights, stakeholder inclusion)\n",
    "\n",
    "### ESG Scoring Rubric (0–5):\n",
    "- **0** – No relevant disclosure.\n",
    "- **1** – ESG topic is mentioned vaguely or once, with no detail.\n",
    "- **2** – Topic is acknowledged; minimal detail or unclear metrics.\n",
    "- **3** – Moderate disclosure; some specificity (e.g. qualitative policies).\n",
    "- **4** – Strong disclosure with specific actions, recent results, or targets.\n",
    "- **5** – Detailed disclosure with metrics, goals, and progress updates.\n",
    "\n",
    "### Output Format:\n",
    "- **ESG Category**: [e.g., Emissions]\n",
    "- **Score (0–5)**: [e.g., 3]\n",
    "- **Justification**: [e.g., “The company mentions carbon emissions and has pledged to reduce them, but no metrics or timeline are provided.”]\n",
    "\n",
    "Be objective. If the company only includes marketing statements or boilerplate language, assign a lower score and explain why.\n",
    "\n",
    "When in doubt, lean toward conservative scoring.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45710d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is tesla's ESG strategy?\"\n",
    "\n",
    "retrieved_docs = local_vector_db.similarity_search(question)\n",
    "docs_content = \"\\n\\n\".join(f\"Document {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs))\n",
    "formated_prompt = prompt.invoke({\"question\": question, \"context\": docs_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3464626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a highly accurate ESG disclosure evaluator, trained to assess company filings for the presence, quality, and materiality of ESG (Environmental, Social, Governance) information.\n",
      "\n",
      "Your task is to analyze retrieved excerpts from 10-K filings and provide a structured evaluation for each ESG dimension or sub-category.\n",
      "\n",
      "You are expected to:\n",
      "1. Identify whether the passage addresses a relevant ESG topic (defined below).\n",
      "2. Judge the quality and detail of the disclosure (is it specific, quantitative, and forward-looking, or vague and generic?).\n",
      "3. Assign a score between 0 and 5 based on the scoring rubric.\n",
      "4. Justify your score in a concise explanation, quoting or paraphrasing the evidence from the text.\n",
      "\n",
      "### ESG Dimensions and Categories (based on LSEG/SASB):\n",
      "\n",
      "**Environmental:**\n",
      "- Emissions (e.g. CO₂ reporting, reduction targets)\n",
      "- Resource Use (e.g. energy/water consumption)\n",
      "- Innovation (e.g. green technologies)\n",
      "\n",
      "**Social:**\n",
      "- Workforce (e.g. diversity, DEI initiatives, labor practi\n"
     ]
    }
   ],
   "source": [
    "print(formated_prompt.to_string()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.invoke(formated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164cfb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Understood? Let's begin!\n",
      "\n",
      "Excerpt 1: \"We are committed to reducing our environmental footprint by implementing sustainable practices across all aspects of our operations.\"\n",
      "\n",
      "*ESG Category*: Environmental - Emissions\n",
      "\n",
      "*Score (0–5)*: 1\n",
      "\n",
      "*Justification*: The statement indicates an intention to address environmental concerns without providing any concrete details about current emission levels, reduction strategies, or timelines. It lacks specificity necessary for meaningful assessment.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
